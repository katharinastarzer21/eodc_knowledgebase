{"version":2,"kind":"Notebook","sha256":"fb3f8c066a68a913da84b2c28fde8a49fd92ef361e9db4e3cd8cec027ce1c0f1","slug":"gfm-maximum-flood-extent-dask","location":"/source/services/GFM/gfm_maximum_flood_extent_dask.ipynb","dependencies":[],"frontmatter":{"title":"EODC Dask Tutorial","subtitle":"In this notebook we demonstrate the basics of using Dask on the EODC cluster.","tags":["GFM","DASK"],"copyright":"Â© 2024 eodc","authors":[{"id":"Author: eodc","name":"Author: eodc"}],"license":{"content":{"id":"MIT","url":"https://opensource.org/licenses/MIT","name":"MIT License","free":true,"osi":true}},"thumbnail":"/e09f7271f6c188a68020a7d6a49ba21c.svg","kernelspec":{"name":"python3","display_name":"default","language":"python"},"numbering":{"title":{"offset":2}},"exports":[{"format":"ipynb","filename":"gfm_maximum_flood_extent_dask.ipynb","url":"/gfm_maximum_flood_ex-01cd9ceca261e28dc7b38a1af8bfe75e.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Dask is a flexible parallel computing library for analytics that enables you to\nscale your computations from a single machine to a cluster. This tutorial will\nguide you through the basics of using Dask on the EODC cluster. The computation\nwill take place on the cluster and you only need to download the result to your\nlocal machine for visualisation or further processing steps. As input data\nfor this tutorial we will use output data from the Global Flood Monitoring (GFM)\nservice.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RdyBMoAAhf"}],"key":"OEAyLrK106"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"As an example, we will calculate the maximum flood extent of a certain time range\nover an area of interest in Pakistan.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"dSWNHnMn3p"}],"key":"FUXCclLtRH"}],"key":"exY9RmCkPG"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Prerequisites","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jwVyUfy80Z"}],"identifier":"prerequisites","label":"Prerequisites","html_id":"prerequisites","implicit":true,"key":"oS5qudkuUq"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Before we start, make sure you have installed all the necessary Python libraries and\npackages with the correct versions. It is important that the cluster and client\n(your machine) have the same versions for the key Python libraries. The easiest\nway is to create a new Python environment with the package manager of your liking.\nSee the required dependencies in the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"awiSf8rUkB"},{"type":"link","url":"https://github.com/eodcgmbh/cluster_image","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"EODC cluster image","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MJ7BIOuwbY"}],"urlSource":"https://github.com/eodcgmbh/cluster_image","error":true,"key":"vBKGebRCxr"},{"type":"text","value":" repository.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Du4vHH5XYo"}],"key":"STyplZ5has"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"In order to spin up a dedicated cluster on the EODC cluster, you will need to\nrequest an EODC account. Please follow the instructions ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"hU0b3CYJBL"},{"type":"link","url":"https://docs.eodc.eu/services/dask.html#who-should-use-dask-gateway-at-eodc","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"here","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"y5WXNMGpqy"}],"urlSource":"https://docs.eodc.eu/services/dask.html#who-should-use-dask-gateway-at-eodc","key":"rfJEk9oCqD"},{"type":"text","value":".","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"z1j4oCcq2Z"}],"key":"VTUItuZZYb"}],"key":"wuHJmy0AH8"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"First some imports","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ajUiFYcPQj"}],"identifier":"first-some-imports","label":"First some imports","html_id":"first-some-imports","implicit":true,"key":"mF0LugqOj1"}],"key":"ek0adxQSTB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import pyproj\nimport rioxarray\nimport xarray as xr\nfrom datetime import datetime\nfrom shapely.geometry import box\nfrom pystac_client import Client\nfrom odc import stac as odc_stac\nimport matplotlib.pyplot as plt\n\nfrom eodc.dask import EODCDaskGateway","key":"vAwxzezgJo"},{"type":"output","id":"PQq6GJhgBfSbYBDi4N6mG","data":[],"key":"Jgf1P2dTJ6"}],"key":"f6qswIlE8I"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Initialize cluster","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hFSawBqIr7"}],"identifier":"initialize-cluster","label":"Initialize cluster","html_id":"initialize-cluster","implicit":true,"key":"TCMmvvM5JQ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Your username of your EODC account come here, usually it is your email address\nyou have used for registration.\nAfter running the next cell, a prompt will open and ask you to enter your\npassword.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jDf593Diey"}],"key":"UmiePuscAX"}],"key":"VcqOgswdln"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"your_username = \"your.email@address.com\"\ngateway = EODCDaskGateway(username=your_username)","key":"IoEzbJ9bSp"},{"type":"output","id":"NPYJD_1qY5dmPfcuBiVnX","data":[],"key":"qUnS71Decc"}],"key":"RvV1yINoZR"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Once authenticated, you can specify the details of your cluster. Specify the\nnumber of cores and size of memory of your worker machines.\nAdditionally, you can specify any public docker image which has the same dask\nversion installed like our Dask cluster. However, we suggest you are using our\ncluster image to avoid errors coming from mismatching software versions.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mAkPHHM3NB"}],"key":"oKHYhuyZVk"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"You will find more detailed information about dask\n","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"hujZU1snzg"},{"type":"link","url":"https://docs.eodc.eu/services/dask.html","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"here","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"lh7F8znbxt"}],"urlSource":"https://docs.eodc.eu/services/dask.html","key":"afxT4yArdJ"},{"type":"text","value":".","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"NqmbPoj40u"}],"key":"X0HylrNVXe"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"The client object provides you with an URL to the dashboard of your current\ncluster. Copy/paste this into your Firefox browser to get an overview what is\ncurrently happening on your cluster.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"tg9v5u7VmD"}],"key":"UwDTBmsLtG"},{"type":"paragraph","position":{"start":{"line":14,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Please make sure to re-use or shutdown an existing cluster, before spawning a\nnew one!","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"bnl3yATlxW"}],"key":"wlF88e9Wo3"}],"key":"cyjYqJHvKc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Define cluster options\ncluster_options = gateway.cluster_options()\n\n# Set the number of cores per worker\ncluster_options.worker_cores = 8\n\n# Set the memory per worker (in GB)\ncluster_options.worker_memory = 16\n\n# Specify the Docker image to use for the workers\ncluster_options.image = \"ghcr.io/eodcgmbh/cluster_image:2025.7.1\"\n\n# Create a new cluster with the specified options\ncluster = gateway.new_cluster(cluster_options)\n\n# Automatically scale the cluster between 1 and 10 workers based on workload\ncluster.adapt(1, 10)  \n\n# Optionally, scale the cluster to use only one worker\n# cluster.scale(1)\n\n# Get a Dask client for the cluster\nclient = cluster.get_client()\nclient.dashboard_link","key":"K11HTSTkv7"},{"type":"output","id":"A7E_bROcFUoa5ZxseWKaV","data":[],"key":"qkUzUDGNbH"}],"key":"DDuxyZTt6a"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Search and load data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SovzEXOcTi"}],"identifier":"search-and-load-data","label":"Search and load data","html_id":"search-and-load-data","implicit":true,"key":"cDJ2KlWDX7"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Now we will define our area (AOI) and time range of interest for which we want\nto calculate the maximum flood extent for.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"r1gCJKa2v7"}],"key":"waFT3YZs68"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"All GFM data is registered as a ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"wBjO4UygX5"},{"type":"link","url":"https://stacspec.org/en/","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"STAC","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"KG0xHI38J1"}],"urlSource":"https://stacspec.org/en/","key":"EtlwTI3WAy"},{"type":"text","value":" collection.\nPlease find more information about STAC in our ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"guSkHeV1RQ"},{"type":"link","url":"https://docs.eodc.eu/services/stac.html","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"documentation","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"dgQ2bZnOBs"}],"urlSource":"https://docs.eodc.eu/services/stac.html","key":"am711FaaJh"},{"type":"text","value":".","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"S9F5K8z5nW"}],"key":"bIvm9OSMjY"}],"key":"DPie7klu81"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Define the API URL\napi_url = \"https://stac.eodc.eu/api/v1\"\n\n# Define the STAC collection ID\ncollection_id = \"GFM\"\n\n# Define the area of interest (AOI) as a bounding box\naoi = box(67.398376, 26.197341, 69.027100, 27.591066)\n\n# Define the time range for the search\ntime_range = (datetime(2022, 9, 1), datetime(2022, 10, 1))\n\n# Open the STAC catalog using the specified API URL\neodc_catalog = Client.open(api_url)\n\n# Perform a search in the catalog with the specified parameters\nsearch = eodc_catalog.search(\n    max_items=1000,             # Maximum number of items to return\n    collections=collection_id,  # The collection to search within\n    intersects=aoi,             # The area of interest\n    datetime=time_range         # The time range for the search\n)\n\n# Collect the found items into an item collection\nitems = search.item_collection()\n\nprint(f\"On EODC we found {len(items)} items for the given search query\")","key":"SZ06WCkvsQ"},{"type":"output","id":"97PTn12rMRQySo0xU0bJK","data":[{"name":"stdout","output_type":"stream","text":"On EODC we found 157 items for the given search query\n"}],"key":"sllGfrn3jP"}],"key":"IEiaA3mvbh"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"We will use the found STAC items to (lazy) load the data into a xarray.Dataset\nobject. In order to achieve this, we need to specify the bands which we want to\nload. To calculate the maximum flood extent, we are interested in the\nâensemble_flood_extentâ layer of each GFM item. Furthermore, we need to specify\nthe coordinate reference system (CRS) as well as the resolution of the data. All\nnecessary metadata is saved in each STAC item.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"F1lHXhv2VJ"}],"key":"LY48ZhLW7e"}],"key":"E9WZV6lESR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Extract the coordinate reference system (CRS) from the first item's properties\ncrs = pyproj.CRS.from_wkt(items[0].properties[\"proj:wkt2\"])\n\n# Set the resolution of the data\nresolution = items[0].properties['gsd']\n\n# Specify the bands to load\nbands = [\"ensemble_flood_extent\"]\n\n# Load the data using odc-stac with the specified parameters\nxx = odc_stac.load(\n    items, \n    bbox=aoi.bounds,   # Define the bounding box for the area of interest\n    crs=crs,   # Set the coordinate reference system\n    bands=bands,   # Specify the bands to load\n    resolution=resolution,   # Set the resolution of the data\n    dtype='uint8',   # Define the data type\n    chunks={\"x\": 1000, \"y\": 1000, \"time\": -1},  # Set the chunk size for Dask\n)\n\n# Extract the 'ensemble_flood_extent' data from the loaded dataset\ndata = xx.ensemble_flood_extent","key":"WyzFmwPr0j"},{"type":"output","id":"trJzYXh7pbqB3NYhR7uRa","data":[],"key":"GGxbeWq9To"}],"key":"SY34yfsXSB"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Process on the cluster","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AXharNvear"}],"identifier":"process-on-the-cluster","label":"Process on the cluster","html_id":"process-on-the-cluster","implicit":true,"key":"CQ6YfZyY5k"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"First, we filter the data to exclude invalid values and calculate the sum along\nthe time dimension. The maximum flood extent refers to the largest area covered\nby flooded pixels during the specified time range. Therefore, we convert the\nresult to a binary mask where each pixel is set to 1 if it was flooded during\nthe specified time range, and 0 if it was not. Then we start the computation on\nthe cluster and save the result as a compressed TIFF file. This file can be\nvisualized in e.g. QGIS.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"o1wqzxeuU0"}],"key":"i769cepsOA"}],"key":"VvlQ6ee0Ps"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Filter the data to exclude values of 255 (nodata) and 0 (no-flood), then sum\n# along the \"time\" dimension \nresult = data.where((data != 255) & (data != 0)).sum(dim=\"time\")\n\n# Convert the result to binary (1 where the sum is greater than 0, otherwise 0)\n# and set the data type to uint8 \nresult = xr.where(result > 0, 1, 0).astype(\"uint8\")\n\n# Compute the result\ncomputed_result = result.compute(sync=True)\n\n# Save the computed result to a GeoTIFF file with LZW compression\ncomputed_result.rio.to_raster(\"./max_flood_pakistan_202209.tif\", compress=\"LZW\")","key":"eymOEX1pmz"},{"type":"output","id":"Jo4PWS3AgxXwzJf0B7RY2","data":[],"key":"XXnJNqNR7N"}],"key":"Rh4G5EmV0q"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Also, we can plot a part of the result with the plotting library matplotlib.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"v3sbJiHgY9"}],"key":"IHF89ZLMhD"}],"key":"GDxPsR9bqB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"plt.figure()\ncomputed_result[:5000, :5000].plot()\nplt.title(\"GFM Maximum Flood Extent\")\nplt.show()","key":"LLHG56MziC"},{"type":"output","id":"eL4a-Cy6I58BPT7Om_hTP","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"3e16acb8284b1be88e42b6dc46e64dfa","path":"/3e16acb8284b1be88e42b6dc46e64dfa.png"},"text/plain":{"content":"<Figure size 640x480 with 2 Axes>","content_type":"text/plain"}}}],"key":"xzi2S77jHP"}],"key":"Eyjd4snFo2"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Shutdown cluster","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SkrHkuhNqc"}],"identifier":"shutdown-cluster","label":"Shutdown cluster","html_id":"shutdown-cluster","implicit":true,"key":"IdpqI7iTGf"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"After successful processing, we need to shutdown our cluster to free up\nresources.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DmMDGNtw2U"}],"key":"rG8OPMq1ON"}],"key":"R5KoDWtAAa"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# After a restart of the Jupyter kernel, the cluster object is gone. Use the\n# following command to connect to the cluster again\n# cluster = gateway.connect(gateway.list_clusters()[0].name)\n\n# Shutdown cluster\ncluster.shutdown()","key":"agIYKOAVGI"},{"type":"output","id":"PV1D3ReuuCYEIXTPfkjIC","data":[],"key":"oP6M4yelX8"}],"key":"tsrVfD16er"}],"key":"Wqa1YSrRF4"},"references":{"cite":{"order":[],"data":{}}}}
{"version":2,"kind":"Article","sha256":"8eb8441fb4914faa13073723a09fbb52ca87da231a11bb871209c97793201521","slug":"argo-workflows","location":"/source/services/ARGO_WORKFLOWS/argo-workflows.md","dependencies":[],"frontmatter":{"title":"Argo Workflows","content_includes_title":true,"numbering":{"title":{"offset":2}},"exports":[{"format":"md","filename":"argo-workflows.md","url":"/argo-workflows-4ded5e52a0dd9d03bfc8b575cb303a6c.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"image","url":"../_static/argo/argo_workflows_logo.png","alt":"argo-workflows-logo","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nFGIt2Rgm4"},{"type":"heading","depth":1,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Argo Workflows","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"RyFB5MOr7Q"}],"identifier":"argo-workflows","label":"Argo Workflows","html_id":"argo-workflows","implicit":true,"key":"vW6Z90ZqXx"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This user documentation provides an overview of using the Argo Workflows deployment at EODC in order to run your earth observation processing at scale.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"kB6cxGTJBY"}],"key":"cvfiH0iPgY"},{"type":"heading","depth":2,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"What is Argo Workflows?","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"uCFlgGLfiU"}],"identifier":"what-is-argo-workflows","label":"What is Argo Workflows?","html_id":"what-is-argo-workflows","implicit":true,"key":"Vwq5b4MwHI"},{"type":"heading","depth":3,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Overview","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"yMbfozVKmQ"}],"identifier":"overview","label":"Overview","html_id":"overview","implicit":true,"key":"Oz4l2LRd9l"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"link","url":"https://argo-workflows.readthedocs.io/en/latest/","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Argo Workflows","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"PK3721Lo9l"}],"urlSource":"https://argo-workflows.readthedocs.io/en/latest/","key":"gEcyoNNJak"},{"type":"text","value":" is an open-source container-native workflow engine designed to orchestrate jobs on Kubernetes. It allows users to define complex workflows as directed acyclic graphs (DAGs), facilitating the automation of multi-step tasks such as data processing and machine learning pipelines. Built to handle large-scale workloads, Argo Workflows is highly efficient for cloud-native applications and integrates seamlessly with Kubernetes environments.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"KJATM48HRB"}],"key":"WNwXiF8dVL"},{"type":"heading","depth":3,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Who Should Use Argo Workflows at EODC?","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"wx5DabcL0n"}],"identifier":"who-should-use-argo-workflows-at-eodc","label":"Who Should Use Argo Workflows at EODC?","html_id":"who-should-use-argo-workflows-at-eodc","implicit":true,"key":"pCbHgpzSwC"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"If any of the following sounds familiar, an Argo Workflow may be right for you.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"snh9qXLPDf"}],"key":"t8cixzVYl2"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":18,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"strong","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Containerization","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"SIPR3fnv10"}],"key":"QMj549axuS"},{"type":"text","value":": Anyone who already has a container, or would like to use an existing container to be run at scale across hundres or thousands of satellite images.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"S1YmfcPzRk"}],"key":"CAPYw5W9bz"}],"key":"nYgLissDrq"},{"type":"listItem","spread":true,"position":{"start":{"line":20,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"strong","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"No python","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"puJm6JPsrC"}],"key":"yAMHlhbg6g"},{"type":"text","value":": Anyone who already has a code base in a language other than python, and can’t leverage the power of Dask. It may be easier to build a run time and tailor a workflow solution instead porting the code to python.","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"bUuINp1P3O"}],"key":"RIes3CRVRo"}],"key":"SoCnIE31W4"},{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"strong","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Regularity","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"g7znDk9cTK"}],"key":"VduLBHTfn0"},{"type":"text","value":": Anyone who would like to run specific processing on a daily, or timely basis, the CronWorkflow would enable you to do that. The results can be uploaded to a S3 bucket and added to a STAC collection automatically.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"H0aAQVMBsc"}],"key":"byRYUBagS8"}],"key":"i9vvSK1tXc"}],"key":"YUU8XxGQ3t"},{"type":"heading","depth":2,"position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Submitting an Argo Workflow","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"rmR3aBYcIW"}],"identifier":"submitting-an-argo-workflow","label":"Submitting an Argo Workflow","html_id":"submitting-an-argo-workflow","implicit":true,"key":"rlbvTD6rXO"},{"type":"heading","depth":3,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Pre-requisite","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"idEYhbzNff"}],"identifier":"pre-requisite","label":"Pre-requisite","html_id":"pre-requisite","implicit":true,"key":"odaGWcaMTY"},{"type":"paragraph","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"You will need to submit a request to the ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"XPTqM8eYRq"},{"type":"link","url":"mailto:support@eodc.eu","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"EODC Support Team","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"lf3Vgo87I5"}],"urlSource":"mailto:support@eodc.eu","key":"k2gzAwAgNn"},{"type":"text","value":" and request access to Argo Workflows. If you want to use argo-workflows via the eodc-sdk, you currently will need a token, make sure to request this in the support request.","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"v88l8cL0AI"}],"key":"wiOPfZa6zt"},{"type":"heading","depth":3,"position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Via the dashboard","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"lqc1Ruy4fh"}],"identifier":"via-the-dashboard","label":"Via the dashboard","html_id":"via-the-dashboard","implicit":true,"key":"WwRySvXFzu"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":33,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":33,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Login to the Argo Workflows ","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"Y8ZUFCP1K4"},{"type":"link","url":"https://services.eodc.eu/workflows/login","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"Dashboard","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"WAcfkvW8ha"}],"urlSource":"https://services.eodc.eu/workflows/login","key":"GDSKxYADnS"},{"type":"text","value":" using the single sign-on option.","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"zRsvd7OWiu"}],"key":"o5hzRDxs2f"}],"key":"j12FPwVjgy"}],"key":"C4lFYPrOxI"},{"type":"image","url":"../_static/argo/login.png","alt":"argo-sso","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"HefLlESCXV"},{"type":"list","ordered":true,"start":2,"spread":false,"position":{"start":{"line":37,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":37,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Navigate to the workflows section of the dashboard. This is the top icon on the sidebar.","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"jLyeXBfJXs"}],"key":"mjJjQpScl1"}],"key":"sGRls7hDvS"}],"key":"UpbpyT4k7C"},{"type":"image","url":"../_static/argo/workflow-dashboard.png","alt":"dashboard-workflows","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"VbX0YiaTZP"},{"type":"list","ordered":true,"start":3,"spread":false,"position":{"start":{"line":41,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":41,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Click ","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"OYSQ0WDXax"},{"type":"emphasis","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"Submit New Workflow","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"DXk7Plvt3D"}],"key":"R4HMeZWKwo"},{"type":"text","value":" a pop up will open. A workflow can either be loaded from a file, or submitted directly as a yaml.","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"Vxfbcs2awy"}],"key":"MqpRoZ9mOx"}],"key":"YKLbiTrjgM"}],"key":"IrgWu7jrMr"},{"type":"image","url":"../_static/argo/create-workflow.png","alt":"alt text","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"dJmuPLgETn"},{"type":"list","ordered":true,"start":4,"spread":false,"position":{"start":{"line":45,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":45,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Once you click create workflow, a new workflow will have appeared. Monitor for its success or failure!","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"eIVdd9kn5n"}],"key":"g7uJAJMsuf"}],"key":"aV73dV9bZB"}],"key":"uMj1j9H4mq"},{"type":"image","url":"../_static/argo/lovely-octopus.png","alt":"alt text","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"j4r7HeVsD6"},{"type":"heading","depth":3,"position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Via the eodc-sdk","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"zMQtVNLMPV"}],"identifier":"via-the-eodc-sdk","label":"Via the eodc-sdk","html_id":"via-the-eodc-sdk","implicit":true,"key":"cvZHkLq3cr"},{"type":"paragraph","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"It’s possible to use the argo workflows deployments at EODC with eodc-sdk version later than 2024.9.1.","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"MUibEiT6BA"}],"key":"aqg9X2gdoC"},{"type":"paragraph","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"text","value":"Refer to the tutorial ","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"u35H0NXTbz"},{"type":"link","url":"../tutorials/eodc_sdk_argo.ipynb","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"text","value":"here","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"pSsKqsBYM9"}],"urlSource":"../tutorials/eodc_sdk_argo.ipynb","key":"sBG9jxhxLY"},{"type":"text","value":".","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"B5rEPw8my3"}],"key":"TlW3htYMY1"}],"key":"LH9U7WvXb3"}],"key":"CLqoqvLZPL"},"references":{"cite":{"order":[],"data":{}}}}